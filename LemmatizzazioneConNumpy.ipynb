{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LemmatizzazioneConNumpy.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPaTyvHYiekF1zg5pWaaDW3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francescosalzano1/md5cracker/blob/master/LemmatizzazioneConNumpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlwFVWuc1OIk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c832c595-9594-4576-8c6d-8bd81802758f"
      },
      "source": [
        "!pip install numpy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr4y1Kdq1TwL"
      },
      "source": [
        "import numpy as np\n",
        "import re"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLIj8sa51VEF"
      },
      "source": [
        "corpus=[\"Salavadanaio beve molto\", \"Paolo beve più di Salvadanaio\", \"Filippo è una cisterna\", \"Elio di Piero è una fabbrica di alcol\", \"Francesco beve il giusto\"]\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJXuN2Nw172E"
      },
      "source": [
        "#definisco una funzione per eseguire la tokenizzazione su spazi\n",
        "\n",
        "def corpus_tokenize(corpus):\n",
        "  tokens=[re.split(\"\\W+\", sent.lower()) for sent in corpus]\n",
        "  return tokens\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Hhk7xO02VXz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2597c66e-86d9-4e81-9272-05bd2b6785e9"
      },
      "source": [
        "corpus_tokens=corpus_tokenize(corpus)\n",
        "print(corpus_tokens)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['salavadanaio', 'beve', 'molto'], ['paolo', 'beve', 'più', 'di', 'salvadanaio'], ['filippo', 'è', 'una', 'cisterna'], ['elio', 'di', 'piero', 'è', 'una', 'fabbrica', 'di', 'alcol'], ['francesco', 'beve', 'il', 'giusto']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiAQ_CCR27NV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "383a14c8-bcf6-41b8-ac6d-491a2d2c429b"
      },
      "source": [
        "def build_vocab(corpus_tokens):\n",
        "  vocab=set({})\n",
        "\n",
        "  for tokens in corpus_tokens:\n",
        "    for token in tokens:\n",
        "      vocab.add(token)\n",
        "\n",
        "  return list(vocab)\n",
        "\n",
        "index_to_word=build_vocab(corpus_tokens)\n",
        "print(vocab)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['francesco', 'molto', 'cisterna', 'elio', 'giusto', 'fabbrica', 'una', 'beve', 'è', 'piero', 'più', 'paolo', 'filippo', 'il', 'salavadanaio', 'salvadanaio', 'alcol', 'di']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d_MSBSN3yrR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00e3142c-f422-4e30-9dd1-a4d299c04ecb"
      },
      "source": [
        "word_to_index= dict([word, i] for i, word in enumerate(index_to_word))\n",
        "word_to_index[\"salvadanaio\"]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1t01Xig7OcY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a6c8e2c-1421-4615-8c1f-a23abc06cb5a"
      },
      "source": [
        "docs_count= len(corpus)\n",
        "print(docs_count)\n",
        "# numero aprole nel vocabolario\n",
        "vocab_size=len(index_to_word)\n",
        "print(vocab_size)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfUBq74q7nAz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96c8fdf9-a87c-4125-e358-dedf0351b833"
      },
      "source": [
        "#creo un'array di zeri\n",
        "#passo numero  delle frasi nel copro come righe e il numero di parole del vocabolario come colonne\n",
        "corpus_bow = numpy.zeros((docs_count,vocab_size))\n",
        "#per vedere la dimensione di un array numpy\n",
        "type(corpus_bow)\n",
        "corpus_bow.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO4e0h7U8MYx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de204e9f-d9c8-45b1-d872-520f1e944d99"
      },
      "source": [
        "#indicizzo tutti i token presenti in corpus_token che contiene la lista di token del corpo di testo\n",
        "#la matrice corpus_bow è riempita di zeri cone zeros()che è una matrice numero delle frasi X numero di parole uniche di tutto il vocabolario \n",
        "#per ogni frase in corpus_tokens, per oni token nelle frasi di corpus_token aumeno di uno lo zero corrispondente a alla riga che identifica la frase e alla colonna data dall'indice del token\n",
        "for i, tokens in enumerate(corpus_tokens):\n",
        "  for token in tokens:\n",
        "    corpus_bow[i][word_to_index[token]]+=1\n",
        "\n",
        "corpus_bow"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
              "        0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 2.],\n",
              "       [1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "        0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1TXzqupCvib"
      },
      "source": [
        "#converto in funzione\n",
        "def bag_of_words(corpus, return_vocab=False):\n",
        "  corpus_tokens=corpus_tokenize(corpus)\n",
        "   \n",
        "\n",
        "  word_to_index= dict([word, i] for i, word in enumerate(index_to_word))\n",
        "\n",
        "  docs_count= len(corpus)\n",
        "# numero parole nel vocabolario\n",
        "  vocab_size=len(index_to_word)\n",
        "\n",
        "  corpus_bow = numpy.zeros((docs_count,vocab_size))\n",
        "  for i, tokens in enumerate(corpus_tokens):\n",
        "    for token in tokens:\n",
        "     corpus_bow[i][word_to_index[token]]+=1\n",
        "\n",
        "  if(return_vocab):\n",
        "    return corpus_bow, index_to_word\n",
        "  else:\n",
        "    return corpus_bow\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljAeIEEtEFvy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40712668-49d9-43c7-837b-8e335aac652c"
      },
      "source": [
        "corpus_bow, vocab= bag_of_words(corpus, return_vocab=True)\n",
        "\n",
        "print(\"Vocabolario:\", vocab)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabolario: ['francesco', 'molto', 'cisterna', 'elio', 'giusto', 'fabbrica', 'una', 'beve', 'è', 'piero', 'più', 'paolo', 'filippo', 'il', 'salavadanaio', 'salvadanaio', 'alcol', 'di']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72-N2QENGDKM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc64851b-d2bd-4bad-86e7-f7a651bb9c5e"
      },
      "source": [
        "# stampo ogni documento del corpo di testo con la sua rappresentazione bag of words\n",
        "#zip fa eseguire ciclo in simultanea su due liste differenti\n",
        "for sent, bow in zip(corpus, corpus_bow):\n",
        "  print(\"Documento:\", sent)\n",
        "  print(\"BAG OF WORDS\", bow)\n",
        "  print(\"---------------\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Documento: Salavadanaio beve molto\n",
            "BAG OF WORDS [0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "---------------\n",
            "Documento: Paolo beve più di Salvadanaio\n",
            "BAG OF WORDS [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1.]\n",
            "---------------\n",
            "Documento: Filippo è una cisterna\n",
            "BAG OF WORDS [0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "---------------\n",
            "Documento: Elio di Piero è una fabbrica di alcol\n",
            "BAG OF WORDS [0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 2.]\n",
            "---------------\n",
            "Documento: Francesco beve il giusto\n",
            "BAG OF WORDS [1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "---------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePK-xlNfpHq-"
      },
      "source": [
        "# Modello TD*IDF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajr48SOFpKWW"
      },
      "source": [
        "corpus_tokens=corpus_tokenize(corpus)\n",
        "index_to_word=build_vocab(corpus_tokens)\n",
        "word_to_index=dict([word,i] for i, word in enumerate(index_to_word))\n",
        "\n",
        "docs_count=len(corpus)\n",
        "vocab_size=len(index_to_word)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xod3WmuFp-r1"
      },
      "source": [
        "#calcolo document frequency\n",
        "#creo array vuto di dim = a quelle del vocabolario\n",
        "df= np.zeros(vocab_size)\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orAhDLC1qOie",
        "outputId": "3a8eb451-2613-4214-b106-b95dbf9408dd"
      },
      "source": [
        "# iteriamo su indici e partole all'interno del vabolario\n",
        "for i,word in enumerate(index_to_word):\n",
        "  #iteriamo su ogni gruppo di token all'interno dei tokens del corpus, se la parola è presente nei token di un documento aumentiamo il contatore\n",
        "  for tokens in corpus_tokens:\n",
        "    if(word in tokens):\n",
        "      df[i]+=1\n",
        "    \n",
        "index_to_word\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['francesco',\n",
              " 'molto',\n",
              " 'cisterna',\n",
              " 'elio',\n",
              " 'giusto',\n",
              " 'fabbrica',\n",
              " 'una',\n",
              " 'beve',\n",
              " 'è',\n",
              " 'piero',\n",
              " 'più',\n",
              " 'paolo',\n",
              " 'filippo',\n",
              " 'il',\n",
              " 'salavadanaio',\n",
              " 'salvadanaio',\n",
              " 'alcol',\n",
              " 'di']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSEhy_rrsDzB",
        "outputId": "7748a4e2-e6a8-46c1-c1e5-560ba64b3cc7"
      },
      "source": [
        "##document\n",
        "df"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1., 1., 2., 3., 2., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ObF8vl-sSzM",
        "outputId": "f75fb895-3c5d-450a-b313-f99b4bee0898"
      },
      "source": [
        "#calcolo idf\n",
        "idf=np.log(docs_count/df)+1\n",
        "idf"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.60943791, 2.60943791, 2.60943791, 2.60943791, 2.60943791,\n",
              "       2.60943791, 1.91629073, 1.51082562, 1.91629073, 2.60943791,\n",
              "       2.60943791, 2.60943791, 2.60943791, 2.60943791, 2.60943791,\n",
              "       2.60943791, 2.60943791, 1.91629073])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIbEq_CHshHg"
      },
      "source": [
        "##calolo term frequency ci dice quante volte un termine appare in un documento\n",
        "tf=np.zeros((docs_count, vocab_size))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljlgnT6Esy2c",
        "outputId": "75fc63a9-6a6c-4b63-aef2-06bdc60376a0"
      },
      "source": [
        "#itero su indici e tokens di ogni documento, contiamo il numero di token sul docuemnto corrente,\n",
        "# iteriamo su ogni token del doc corrente, ottengo l'indice del token corrente e aggiungo 1(tipo BOG) \n",
        "#alla fine divido il valore di ognli elemento per la lunghezza della lista del nunmero di parole che compongono il docuemnto\n",
        "for i, tokens in enumerate(corpus_tokens):\n",
        "  word_counts=len(tokens)\n",
        "  for token in tokens:\n",
        "    tf[i][word_to_index[token]]+=1\n",
        "  tf[i]/=word_counts\n",
        "\n",
        "tf"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.33333333, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.33333333, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.33333333,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.2       , 0.        , 0.        ,\n",
              "        0.2       , 0.2       , 0.        , 0.        , 0.        ,\n",
              "        0.2       , 0.        , 0.2       ],\n",
              "       [0.        , 0.        , 0.25      , 0.        , 0.        ,\n",
              "        0.        , 0.25      , 0.        , 0.25      , 0.        ,\n",
              "        0.        , 0.        , 0.25      , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.125     , 0.        ,\n",
              "        0.125     , 0.125     , 0.        , 0.125     , 0.125     ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.125     , 0.25      ],\n",
              "       [0.25      , 0.        , 0.        , 0.        , 0.25      ,\n",
              "        0.        , 0.        , 0.25      , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.25      , 0.        ,\n",
              "        0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xs5c6j6vvsnQ",
        "outputId": "c3268e1b-12ba-4f15-d241-0fa5dd4b7077"
      },
      "source": [
        "#calcolo tf*idf\n",
        "tf_idf=df*idf\n",
        "tf"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.33333333, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.33333333, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.33333333,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.2       , 0.        , 0.        ,\n",
              "        0.2       , 0.2       , 0.        , 0.        , 0.        ,\n",
              "        0.2       , 0.        , 0.2       ],\n",
              "       [0.        , 0.        , 0.25      , 0.        , 0.        ,\n",
              "        0.        , 0.25      , 0.        , 0.25      , 0.        ,\n",
              "        0.        , 0.        , 0.25      , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.125     , 0.        ,\n",
              "        0.125     , 0.125     , 0.        , 0.125     , 0.125     ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.125     , 0.25      ],\n",
              "       [0.25      , 0.        , 0.        , 0.        , 0.25      ,\n",
              "        0.        , 0.        , 0.25      , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.25      , 0.        ,\n",
              "        0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF1EzhCMv7CR",
        "outputId": "a2df4b16-9de1-4a26-9d28-cf6534cf745c"
      },
      "source": [
        "#commenti e dettagli\n",
        "idf.shape\n",
        "tf.shape\n",
        "#lo shape è dicerso! idf è un vettore lungo 18, tf è una matrice 5X18\n",
        "#nel moemnto in cui facciamo tf*idf numopy esegue la moltiplicazione valore per valore. per ottenre la prima riga ogni elemento della prima riga della matrice viene moltiplicato con l'iesimo dell'array, stesso per la seconda riga da 1 a 18 esimo elemento"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtPRMzRhzYdK"
      },
      "source": [
        "##metto tutto in una funzionne\n",
        "def np_tf_idf(corpus):\n",
        "  \n",
        "  corpus_tokens = corpus_tokenize(corpus)\n",
        "  \n",
        "  index_to_word = build_vocab(corpus_tokens)\n",
        "  word_to_index = dict([(char, i) for i, char in enumerate(index_to_word)]) # creiamo il vocabolario inverso\n",
        "  \n",
        "  vocab_size = len(index_to_word)\n",
        "  docs_count = len(corpus)\n",
        "  \n",
        "  # Document Frequency\n",
        "    \n",
        "  df = np.zeros(vocab_size)\n",
        "\n",
        "  for i,word in enumerate(index_to_word):\n",
        "    for tokens in corpus_tokens:\n",
        "      if(word in tokens):\n",
        "        df[i]+=1\n",
        "\n",
        "  # Inverse Document frequency\n",
        "        \n",
        "  idf = np.log(docs_count/df)+1\n",
        "\n",
        "  # Term Frequency\n",
        "  \n",
        "  tf = np.zeros((docs_count, vocab_size))\n",
        "  \n",
        "  for i, tokens in enumerate(corpus_tokens):\n",
        "    word_counts = len(tokens)\n",
        "    for token in tokens:\n",
        "      tf[i][word_to_index[token]]+=1 # usiamo il vocabolario inverso\n",
        "    tf[i]/=word_counts\n",
        "\n",
        "  #TF-IDF\n",
        "    \n",
        "  tf_idf = tf*idf\n",
        "\n",
        "  return tf_idf, index_to_word\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0ytNrfV2wO7",
        "outputId": "86bec38d-2fe2-43ca-d967-e816ea6d4019"
      },
      "source": [
        "corpus_tfidf, vocab = np_tf_idf(corpus)\n",
        "\n",
        "print(\"Dizionario:\",vocab)\n",
        "print(\"\\n\")\n",
        "\n",
        "for sent, tfidf in zip(corpus, corpus_tfidf):\n",
        "  print(\"Frase:\", sent)\n",
        "  print(\"TF-IDF:\", tfidf)\n",
        "  print(\"-------\")"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dizionario: ['francesco', 'molto', 'cisterna', 'elio', 'giusto', 'fabbrica', 'una', 'beve', 'è', 'piero', 'più', 'paolo', 'filippo', 'il', 'salavadanaio', 'salvadanaio', 'alcol', 'di']\n",
            "\n",
            "\n",
            "Frase: Salavadanaio beve molto\n",
            "TF-IDF: [0.         0.86981264 0.         0.         0.         0.\n",
            " 0.         0.50360854 0.         0.         0.         0.\n",
            " 0.         0.         0.86981264 0.         0.         0.        ]\n",
            "-------\n",
            "Frase: Paolo beve più di Salvadanaio\n",
            "TF-IDF: [0.         0.         0.         0.         0.         0.\n",
            " 0.         0.30216512 0.         0.         0.52188758 0.52188758\n",
            " 0.         0.         0.         0.52188758 0.         0.38325815]\n",
            "-------\n",
            "Frase: Filippo è una cisterna\n",
            "TF-IDF: [0.         0.         0.65235948 0.         0.         0.\n",
            " 0.47907268 0.         0.47907268 0.         0.         0.\n",
            " 0.65235948 0.         0.         0.         0.         0.        ]\n",
            "-------\n",
            "Frase: Elio di Piero è una fabbrica di alcol\n",
            "TF-IDF: [0.         0.         0.         0.32617974 0.         0.32617974\n",
            " 0.23953634 0.         0.23953634 0.32617974 0.         0.\n",
            " 0.         0.         0.         0.         0.32617974 0.47907268]\n",
            "-------\n",
            "Frase: Francesco beve il giusto\n",
            "TF-IDF: [0.65235948 0.         0.         0.         0.65235948 0.\n",
            " 0.         0.37770641 0.         0.         0.         0.\n",
            " 0.         0.65235948 0.         0.         0.         0.        ]\n",
            "-------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}